在GitHub Universe 2018上，GitHub在beta中启动了GitHub Actions。 GitHub在2019年8月下旬宣布扩展GitHub Actions，以包括持续集成/持续交付（CI / CD）。 在2019年Universe上，GitHub [宣布](https://github.blog/2019-11-13-universe-day-one/#github-actions) Actions已超出beta版本且可普遍使用。 在感恩节放假期间，我花了最后几天来探索GitHub Actions，以实现Python项目的自动化。

在参与 [Gaphor](https://gaphor.org) 项目的过程中，我们有一个GUI应用程序要 [维护](https://github.com/gaphor/gaphor) ，还有两个库，一个名为 [Gaphas](https://github.com/gaphor/gaphas) 的图表小部件 ，最近，我们接管了一个库，该库启用了多 [调度](https://github.com/gaphor/gaphas) 和事件 [Generic](https://github.com/gaphor/generic) 。 重要的是要有一个高效的编程工作流程来维护这些项目，因此我们可以花更多的开源志愿者时间专注于实现新功能和编程的其他令人愉悦的部分，而减少进行手动和无聊的项目维护的时间。

在这篇博客文章中，我将概述CI / CD是什么，我以前在其他CI / CD系统上的经验，如何使用GitHub Actions测试和部署Python应用程序和库，最后重点介绍一些其他可以用于自动化Python工作流程的其他部分。

### CI / CD概述

持续集成（CI）是经常将代码更改与现有代码存储库集成在一起的做法。

![持续集成](https://dan.yeaw.me/images/continuous-integration.svg)

然后，连续交付/交付（CD）通过确保检入到master分支的软件始终处于要交付给用户的状态来扩展CI，并使部署过程自动化。

![持续交付/部署](https://dan.yeaw.me/images/continuous-delivery-deployment.svg)

对于GitHub或GitLab上的开源项目，工作流程通常如下：

1.  最新的开发是在称为master的主线分支上。
2.  贡献者创建他们自己的项目副本，称为fork，然后将其fork复制到本地计算机并设置开发环境。
3.  贡献者在他们的计算机上创建一个本地分支，以进行他们想要进行的更改，为更改添加测试，然后进行更改。
4.  一旦所有单元测试均在本地通过，他们将提交更改并将其推送到其分支上的新分支。
5.  他们打开对原始存储库的请求请求。
6.  “拉取请求”会自动在CI系统上启动构建，运行格式设置和其他棉绒检查，并运行所有测试。
7.  一旦所有测试通过，并且项目的维护人员对更新感到满意，他们会将更改合并回master分支。

要么以固定的发布节奏，要么偶然地，维护者随后将版本标签添加到master，然后启动CD系统以打包并向用户发布新版本。

### 我在其他CI / CD系统上的经验

由于大多数开源项目都不希望使用诸如Jenkins之类的软件来维护自己的本地CI服务器的开销，因此在过去7年中，基于云或托管CI服务的使用变得非常流行。 其中最常用的是Travis CI，Circle CI紧随其后。 尽管这两种服务在去年都引入了对Windows的初始支持，但是大多数用户仅在Linux和macOS上运行测试。 如果使用Travis或Circle的项目需要在Windows上进行测试，通常会使用另一项称为AppVeyor的服务。

我认为Travis CI和其他类似服务的普及是基于它们的易用性。 您将使用GitHub帐户登录该服务，告诉该服务测试您的一个项目，使用其中一个示例将YAML格式的文件添加到您的存储库，然后推送到软件存储库（回购）以触发您的第一个构建。 尽管这些服务仍然非常受欢迎，但2019年是他们开始失去部分动力的一年。 2019年1月，一家名为Idera的公司收购了Travis CI。 然后，Travis CI在2月 [解雇](https://twitter.com/alicegoldfuss/status/1098604563664420865) 了许多高级工程师和技术人员。

800磅的大猩猩于2018年进入这个领域，当时微软在6月收购了GitHub，然后将其Visual Studio Team Services生态系统重新命名，并在9月启动了Azure Pipelines作为CI服务。 像大多数流行的服务一样，它对开源项目是免费的。 该服务的显着特征是它启动了支持Linux，macOS和Windows的功能，并且允许10个并行作业。 尽管其他服务提供了并行构建，但是在某些平台上，它们仅适用于开源项目，因此我经常会等待Travis CI提供称为“代理”的服务器。 在Travis CI裁员之后，我准备探索其他要使用的服务，而Azure Pipelines是新的热门CI系统。

在花了几年时间将其更新为Python 3和PyGObject之后，我准备在2019年3月发布Gaphor的1.0.0版本。 我们一直在使用Travis CI，但缺乏在所有三个主要平台上测试和打包应用程序的能力。 我以此为契机学习Azure Pipelines，以期能够填补工作流中的空白。

我从这次经验中得出的结论是，与Travis CI相比，Azure Pipelines缺乏很多易用性，但还具有其他巨大优势，包括构建速度以及创建复杂的跨平台工作流的灵活性和强大功能。 在这些CI系统中的任何一个上开发复杂的工作流程都是具有挑战性的，因为您收到的反馈需要很长时间才能返回给您。 为了创建工作流程，我通常：

1.  创建我正在处理的项目的分支
2.  根据可用的文档和示例开发YAML配置
3.  推送到分支，启动CI构建
4.  等待构建运行10分钟后，意识到有些东西没有按预期工作
5.  返回第2步，重复一遍又一遍

我的其他主要收获之一是，该文档通常缺少复杂工作流程的良好示例，并且不清楚如何使用每个步骤。 这带来了更多的反复试验，在您开发解决方案时需要很大的耐心。 经过大量的努力，我得以完成在Linux，macOS和Windows上测试Gaphor的配置。 当我按下新版本标签时，我还可以通过设置管道以将macOS的内置dmg文件添加到草稿版本中来部分使CD正常工作。 几周前，我还能够构建和上传Python Wheel和源代码分发，以及在 [MSYS2中](https://www.msys2.org) 构建的Windows二进制文件 。

尽管面临挑战，但结果还是非常好！ 对于复杂的工作流（25分钟至12分钟），Azure Pipelines的尖叫速度很快，大约是Travis CI的两倍。 允许在所有三个主要平台上进行测试的紧密集成也是我一直在寻找的东西。

### 如何使用GitHub Actions测试Python库

在没有任何背景知识的情况下，现在进入GitHub Actions。 尽管我对Azure Pipelines的性能感到非常满意，但我认为将东西更好地结合Travis CI的易用性与Azure Pipelines提供的功能将是一件很不错的事情。 在尝试替换帖子开头提到的三个Gaphor项目上的Travis和Pipelines之前，我没有使用任何操作。

我首先从库开始，以便尝试GitHub Actions尝试转换Gaphor本身之前，先尝试一些更简单的工作流程。 Gaphas和Generic都使用Travis CI。 对于Python包，工作流程非常标准：

1.  使用 [pre\-commit](https://pre-commit.com) 运行lint 以 在代码库 上运行 [Black](https://black.rtd.io)
2.  使用矩阵构建来使用Python 2.7、3.6、3.7和3.8测试库
3.  上传覆盖率信息

要开始使用项目上的GitHub Actions，请转到主存储库上的Actions选项卡：

![GitHub动作标签](https://dan.yeaw.me/images/github-actions-tab.png)

基于您的项目主要由Python组成，GitHub将建议三个不同的工作流，您可以将它们用作模板来创建自己的工作流：

1.  Python应用程序\-在单个Python版本上进行测试
2.  Python套件\-在多个Python版本上测试
3.  发布Python软件包\-使用Twine将软件包发布到PyPI

以下是我想到的工作流程：

![图书馆工作流程](https://dan.yeaw.me/images/library-workflow.svg)

我想从运行的皮棉作业开始，一旦成功完成，我想使用库支持的多个Python版本开始并行作业。

对于这些库，第二个工作流程是我想要的最接近的工作流程，因为我想在多个版本的Python上进行测试。 我选择了该 `Set up this workflow` 选项。 GitHub然后根据您选择的模板创建一个新的YAML草稿文件，并将其放置 `.github/workflows` 在您的仓库 中的 目录中。 在屏幕顶部，您还可以将YAML文件的名称从更改为 `pythonpackage.yml` 您选择的任何文件名。 我称呼我为我 `build.yml` ，因为将这种类型的工作流程称为构建是我熟悉的术语。

附带说明一下，GitHub为创建Actions而实现的在线编辑器相当不错。 它包括完整的自动完成功能（通过Ctrl + Space切换），并且可以主动突出显示YAML文件中的错误，以确保每个工作流程的语法正确。 由于较长的反馈循环，这些类型的错误检查是无价的，因此我实际上建议此时使用VSCode或Pycharm提供的内容的在线编辑器。

#### 在事件上执行

每个工作流程文件的顶部都有两个关键字： `name` 和 `on` 。 该 `name` 怎样将显示在操作选项卡为您所创建的工作流程设置。 如果您没有定义名称，那么将在Action运行时显示YAML文件的名称。 该 `on` 关键字定义什么会导致工作流程启动。 模板使用的值为 `push` ，这意味着当您推送到存储库中的任何分支时，将启动工作流程。 这是如何为库设置这些设置的示例：

name: Build
on:
  pull\_request:
  push:
    branches: master

我不想在任何推送事件上运行此工作流，而是希望在两种情况下进行构建：

1.  任何拉取请求
2.  任何推送到master分支

您可以查看上面的配置方式。 能够在GitHub中的任何类型的事件上启动工作流的功能非常强大，这是GitHub Actions具有紧密集成的优点之一。

#### 皮棉乔布

YAML文件的下一部分称为 `jobs` ，这是工作流的每个主要块都将被定义为作业的地方。 然后，这些作业将进一步细分为多个步骤，并且可以在每个步骤中执行多个命令。 您定义的每个作业都有一个名称。 在模板中，作业名为 `build` ，但此名称没有任何特殊意义。 他们还为每个要测试的Python版本运行了一个细小的步骤。 我决定我希望一次运行lint作为一项单独的工作，然后在完成后就可以并行启动所有测试。

为了将棉绒添加为单独的作业，我在 关键字中 创建了一个名为 `lint` nested 的新作业 `jobs` 。 以下是我的皮棉工作示例：

jobs:
  lint:
    runs\-on: ubuntu\-latest
    steps:
      \- uses: actions/checkout@v1
      \- name: Setup Python
        uses: actions/setup\-python@v1
        with:
          python\-version: '3.x'
      \- name: Install Dependencies
        run: |
          pip install pre\-commit
          pre\-commit install\-hooks
      \- name: Lint with pre\-commit
        run: pre\-commit run \-\-all\-files

接下来是 `runs-on` 关键字，它定义了GitHub Actions将在哪个平台上运行此作业，在这种情况下，我将在最新的Ubuntu版本上运行linting。 该 `steps` 关键字是大多数工作流的内容将是，因为它定义，因为它在运行时将执行的每个步骤。 每个步骤都可以选择获得一个名称，然后定义要使用的操作或要运行的命令。

让我们从动作开始，因为它们是我皮棉工作的前两个步骤。 动作的关键字是 `uses` ，值是动作回购名称和版本。 我将Actions视为一个库，这是一个可重用的步骤，可以在CI / CD管道中使用它，而无需重新发明轮子。 GitHub开发了我正在使用的前两个Action，但是稍后您将看到可以使用其他用户发布的任何Action，甚至可以使用Actions SDK和某些TypeScript创建自己的Action。 我现在确信这是GitHub Actions的“秘密秘诀”，这将使此服务真正与众不同。 稍后我将讨论更多。

我正在使用的前两个动作从存储库中克隆了我正在测试的代码的副本，并设置了Python。 动作通常使用 `with` 关键字作为配置选项，在这种情况下，我告诉 `setup-python` 动作使用来自Python 3的较新版本。

      \- uses: actions/checkout@v1
      \- name: Setup Python
        uses: actions/setup\-python@v1
        with:
          python\-version: '3.x'

整理作业的最后两个步骤是使用 `run` 关键字。 在这里，我正在定义要执行的动作未包含的命令。 如前所述，我正在使用pre\-commit在项目上运行Black，并检查代码格式是否正确。 我将其分为两个步骤：

1.  安装依赖项\-安装预提交和预提交挂钩环境
2.  带有预提交的Lint\-对仓库中的所有文件运行Black

在“ *安装依赖关系”* 步骤中，我还将使用管道运算符“ |”，它表示我正在给出多个命令，并且将每个命令都分隔在新的一行上。 现在，我们应该为Python库准备一个完整的lint作业，如果您还没有的话，现在是提交并将更改推送到分支的好时机，并检查lint作业是否通过了您的回购。

#### 测试工作

对于测试作业，我创建了另一个名为 的作业，该作业 `test` 也使用该 `ubuntu-latest` 平台。 我确实在这里使用了一个新的关键字 `needs` 。 这定义了该作业仅应在棉绒作业成功完成后才能开始。 如果我不包括在内，则皮棉作业和所有其他测试作业将同时开始。

  test:
    needs: lint
    runs\-on: ubuntu\-latest

接下来，我使用了另一个名为的新关键字 `strategy` 。 策略会为您的工作创建构建矩阵。 构建矩阵是用于作业的虚拟环境的一组不同配置。 例如，您可以针对多个操作系统，工具版本或在这种情况下针对不同版本的Python运行作业。 这样可以防止重复，因为否则您将需要为不同版本的Python反复复制和粘贴相同的步骤。 最后，我们使用的模板还有一个max\-parallel关键字，它限制了可以同时运行的并行作业的数量。 我仅使用四个版本的Python，没有任何理由限制并行作业的数量，因此我为YAML文件删除了这一行。

    strategy:
      matrix:
        python\-version: \[2.7, 3.6, 3.7, 3.8\]

现在进入工作步骤。 我的前两个步骤（签出源代码和设置Python）与上面在lint作业中所做的步骤相同。 有一个区别，那就是我 `${{ matrix.python-version }}` 在设置Python步骤中 使用了 语法。 我使用{{}}语法定义一个表达式。 我正在使用一种特殊的表达式，称为上下文，它是一种从我之前配置的矩阵参数访问有关工作流运行，虚拟环境，作业，步骤以及在这种情况下的Python版本信息的信息的方式。 最后，我在上下文表达式前面使用$符号来告诉Actions将表达式扩展为其值。 如果当前从矩阵运行python的3.8版，则将 `${{ matrix.python-version }}` 其替换为 `3.8` 。

    steps:
      \- uses: actions/checkout@v1
      \- name: Set up Python ${{ matrix.python\-version }}
        uses: actions/setup\-python@v1
        with:
          python\-version: ${{ matrix.python\-version }}

由于我正在测试GTK图表库，因此我还需要安装一些Ubuntu依赖项。 我使用 `>` 符号作为YAML语法来忽略运行值中的换行符，这使我可以执行非常长的命令，同时将标准行长保留在.yml文件中。

      \- name: Install Ubuntu Dependencies
        run: \>
          sudo apt\-get update \-q && sudo apt\-get install
          \-\-no\-install\-recommends \-y xvfb python3\-dev python3\-gi
          python3\-gi\-cairo gir1.2\-gtk\-3.0 libgirepository1.0\-dev libcairo2\-dev

对于我的项目，我喜欢使用Poetry来管理我的Python依赖项。 有关 如何在项目中使用诗歌的更多信息， 请参见我的另一篇有关“ [用诗歌和公文包](https://dan.yeaw.me/posts/python-packaging-with-poetry-and-briefcase/) 进行 [Python打包”的](https://dan.yeaw.me/posts/python-packaging-with-poetry-and-briefcase/) 文章 。 我正在使用 [Daniel Schep](https://github.com/dschep) 创建 的自定义动作 来安装Poetry。 尽管手动安装Poetry非常简单，但我非常喜欢能够利用其他人创建的这些构建基块。 尽管在本地开发环境上工作时应始终使用Python虚拟环境，但实际上并不需要它们，因为为CI / CD创建的环境已被隔离并且不会被重复使用。 这对会是一个不错的改进 `install-poetry-action` ，因此默认情况下将关闭virtualenvs的创建。

      \- name: Install Poetry
        uses: dschep/install\-poetry\-action@v1.2
        with:
          version: 1.0.0b3
      \- name: Turn off Virtualenvs
        run: poetry config virtualenvs.create false

接下来，我们 `poetry.lock` 使用 `poetry install` 命令 Poetry使用 文件 安装依赖项 。 然后，我们进入了工作的关键步骤，那就是使用Pytest运行所有测试。 我给 `pytest` 命令加上 了 前缀， `xvfb-run` 因为这是一个GUI库，并且由于没有在CI运行程序上运行的显示服务器（如X或Wayland），许多测试都会失败。 X虚拟帧缓冲区（Xvfb）显示服务器用于执行内存中的所有图形操作，而不显示任何屏幕输出。

      \- name: Install Python Dependencies
        run: poetry install
      \- name: Test with Pytest
        run: xvfb\-run pytest

测试阶段的最后一步是上传代码覆盖率信息。 我们正在使用 [Code Climate](https://codeclimate.com/oss/) 分析覆盖率，因为它还基于代码气味和它检测到的重复项集成了不错的可维护性评分。 我发现这是一个很好的工具，可以帮助我们集中精力进行重构和其他维护工作。 [工作服](https://coveralls.io) 和 [Codecov](https://codecov.io) 是，我已经使用，以及不错的选择。 为了在Pytest运行时记录代码覆盖率信息，我使用了 [pytest\-cov](https://pytest-cov.rtd.io) Pytest插件。

      \- name: Code Climate Coverage Action
        uses: paambaati/codeclimate\-action@v2.3.0
        env:
          CC\_TEST\_REPORTER\_ID: 195e9f83022747c8eefa3ec9510dd730081ef111acd99c98ea0efed7f632ff8a
        with:
          coverageCommand: coverage xml

#### CD工作流程\-上传到PyPI

我正在为我的应用程序使用第二个工作流，而实际上对于图书馆而言，该工作流会更多一些，因此在此进行介绍。 Python包索引（PyPI）通常是我们在Python项目之间共享库的方式，它是从运行时开始安装库的位置 `pip install` 。 准备好发布库的新版本后，我希望CD管道将其自动上传到PyPI。

如果您回想起以前，第三个GitHub Action Python工作流程模板称为Publish Python Package。 该模板与我的用例非常接近，除了我使用诗歌来构建和上载而不是使用 `setup.py` 构建和Twine上载之外。 我还使用了稍有不同的事件触发器。

on:
  release:
    types: published

这将我的工作流设置为在我完全发布GitHub版本时执行。 “发布Python包”模板 `created` 改为 使用该事件 。 但是，发布新版本，然后将其上传到PyPI，而不是上传到PyPI然后发布，对我来说更有意义。 将版本上传到PyPI后，将无法重新上传，必须创建新版本才能再次上传。 换句话说，我最喜欢最后一步。

在进入最后一步之前，其余的工作流程应看起来与测试工作流程非常相似：

jobs:
  deploy:
    runs\-on: ubuntu\-latest
    steps:
    \- uses: actions/checkout@v1
    \- name: Set up Python
      uses: actions/setup\-python@v1
      with:
        python\-version: '3.x'
    \- name: Install Poetry
      uses: dschep/install\-poetry\-action@v1.2
      with:
        version: 1.0.0b3
    \- name: Install Dependencies
      run: poetry install
    \- name: Build and publish
      run: |
        poetry build
        poetry publish \-u ${{ secrets.PYPI\_USERNAME }} \-p ${{ secrets.PYPI\_PASSWORD }}

工作流的最后一步使用 `poetry publish` 命令将Wheel和sdist上传到PyPI。 我 通过转到存储库设置，然后选择Secrets，并定义了仅在此工作流程中公开的两个新的加密环境变量，来 定义 `secrets.PYPI_USERNAME` 和 `secrets.PYPI_PASSWORD` 上下文表达式。 如果贡献者从此仓库的分支创建了“拉取请求”，则不会将机密传递给从“拉取请求”开始的任何工作流程。 通过 命令 的 `-u` 和 `-p` 选项 传递的这些机密 `publish` 用于与PyPI服务器进行身份验证。

至此，我们完成了测试和发布库的配置。 提交更改并将其推送到分支，并确保所有步骤都成功通过。 这是输出在GitHub中的“动作”选项卡上的样子：

![GitHub动作输出](https://dan.yeaw.me/images/github-actions-output.png)

我已经在 [Gaphas存储](https://github.com/gaphor/gaphas/tree/master/.github/workflows) 库中发布了Python库的完整GitHub Actions工作流的最终版本 。

### 如何使用GitHub Actions测试和部署Python应用程序

我测试跨平台Python应用程序的用例与我们先前针对库所见的用例稍有不同。 对于该库，我们在所有受支持的Python版本上进行测试非常重要。 对于应用程序，我将其运行所在平台的应用程序与我希望应用程序使用的Python版本（通常是Python的最新稳定版本）打包在一起。 因此，与使用多个版本的Python进行测试相比，确保测试在应用程序将要运行的所有平台上通过，然后为每个平台打包和部署应用程序变得更加重要。

下面是我要创建的两个管道，一个用于CI，一个用于CD。 尽管您可以将它们组合到单个管道中，但我喜欢GitHub Actions在定义任何GitHub事件以启动工作流方面具有很大的灵活性。 这种紧密的集成无疑是一个巨大的收获，它使您可以使每个工作流程更加原子化和易于理解。 我为 `build.yml` CI部分和 `release.yml` CD部分 命名了两个工作流程 。

![应用程式工作流程](https://dan.yeaw.me/images/app-workflow.svg)

#### 缓存Python依赖项

尽管在库和应用程序之间，lint阶段是相同的，但是我将添加一个可选的缓存步骤，为简化起见，我没有包括它：

      \- name: Use Python Dependency Cache
        uses: actions/cache@v1.0.3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}\-pip\-${{ hashFiles('\*\*/poetry.lock') }}
          restore\-keys: ${{ runner.os }}\-pip\-

使用高速缓存存储构建中不经常更改的信息（如Python依赖项）是一个好习惯。 它可以帮助加快构建过程并减轻PyPI服务器上的负载。 进行设置时，我还从 [Travis CI文档](https://docs.travis-ci.com/user/caching/#things-not-to-cache) 中 了解到 ，您不应该缓存大型文件，这些文件可以快速安装，但下载速度较慢，例如Ubuntu软件包和docker映像。 这些文件从缓存中下载所需的时间与从原始源中下载它们所花费的时间一样长。 这就解释了为什么缓存操作没有有关缓存这些类型文件的任何示例。

缓存通过检查工作流程开始时是否存在缓存的存档来工作。 如果存在，它将下载并将其解压缩到路径位置。 在工作流结束时，该操作将检查以前是否存在缓存，如果不存在，则将其称为缓存未命中，它将创建一个新的存档并将其上传到远程存储。

注意一些配置， `path` 它依赖 于 操作系统，因为pip将其缓存存储在不同的位置。 我上面的配置适用于Ubuntu，但您需要 `~\AppData\Local\pip\Cache` 用于Windows和 `~/Library/Caches/pip` macOS。 该 `key` 用于确定是否存在用于恢复和保存到正确的缓存。 由于我使用Poetry进行依赖项管理，因此我将 `poetry.lock` 文件 的哈希值 添加到密钥的末尾，该密钥包含作业在其上运行的操作系统的上下文表达式 `runner.os` 和pip。 看起来像 `Windows-pip-45f8427e5cd3738684a3ca8d009c0ef6de81aa1226afbe5be9216ba645c66e8a` ，结尾是长哈希。 这样，如果我的项目依赖项发生变化，我的 `poetry.lock` 将被更新，并且将创建一个新的缓存，而不是从旧的缓存中还原。 如果您不使用诗歌，也可以将您的 `requirements.txt` 或 `Pipfile.lock` 用于相同的目的。

如前所述，如果 `key` 与现有的缓存不匹配，则称为缓存未命中。 最终配置选项 `restore-keys` 是可选的，它提供了用于还原缓存的键的有序列表。 它通过顺序搜索在“还原键”列表中部分匹配的所有缓存来做到这一点。 如果某个键部分匹配，则该操作将下载存档文件并解压缩以供使用，直到在工作流结束时上传新的缓存为止。

#### 测试工作

理想情况下，使用构建矩阵在各个平台上进行测试将是很棒的。 这样，您无需为每个平台重复执行类似的构建步骤。 看起来像这样：

runs\-on: ${{ matrix.os }}
strategy:
    matrix:
        os: \[ubuntu\-latest, windows\-latest, macOS\-latest\]
steps:
    \- name: Install Ubuntu Dependencies
      if: matrix.os == 'ubuntu\-latest'
      run: \>
        sudo apt\-get update \-q && sudo apt\-get install
        \-\-no\-install\-recommends \-y xvfb python3\-dev python3\-gi
        python3\-gi\-cairo gir1.2\-gtk\-3.0 libgirepository1.0\-dev libcairo2\-dev
    \- name: Install Brew Dependencies
      if: matrix.os == 'macOS\-latest'
      run: brew install gobject\-introspection gtk+3 adwaita\-icon\-theme

注意 `if` 关键字test当前正在使用哪个操作系统，以便为每个平台修改命令。 如前所述，我正在开发的GTK应用程序需要 [MSYS2](https://www.msys2.org) 才能针对Windows进行测试和打包。 由于MSYS2是一个小众平台，因此大多数步骤都是唯一的，并且需要手动设置路径并执行Shell脚本。 在某个时候，也许我们可以将这些独特的部分更好地包装在一个动作中，这样，当我们抽象出这些步骤时，它们在平台之间会变得更加常见。 现在，在我的案例中，为每个操作系统使用一个矩阵并不比仅创建三个单独的作业（每个平台一个作业）容易。

如果您对更复杂的矩阵设置感兴趣，那么Jeff Triplett会 [发布](https://twitter.com/webology/status/1201887760413528065?s=20) 他的配置，以针对五个不同的Python版本运行五个不同的Django版本。

这三个测试作业的实现与我们之前看过的库测试作业相似。

test\-linux:
  needs: lint
  runs\-on: ubuntu\-latest
...
test\-macos:
  needs: lint
  runs\-on: macOS\-latest
...
test\-windows:
  needs:lint
  runs\-on: windows\-latest

安装依赖项，设置缓存以及使用Pytest进行测试的其他步骤是相同的​​。

#### CD工作流程\-释放应用安装程序

现在，我们已经完成了针对CD应用程序的Python应用程序的CI工作流程。 此工作流程使用不同的事件触发器：

name: Release

on:
  release:
    types: \[created, edited\]

GitHub有一个“发布”选项卡，该选项卡内置在每个存储库中。 如果创建或修改发行版，则会在此处启动部署工作流程。 您可以定义多个事件来启动工作流程，方法是将它们添加为逗号分隔的列表。 当我想发布Gaphor的新版本时：

1.  我在中更新版本号 `pyproject.toml` ，提交更改，添加版本标签，最后推送提交和标签。
2.  测试通过后，我将编辑先前草拟的发行版，以将标记指向发行版的标记。
3.  发布工作流程会自动构建并上传Python Wheel和sdist，macOS dmg和Windows安装程序。
4.  准备就绪后，单击GitHub选项以发布版本。

为了实现此工作流程，首先我们为Windows和macOS创建一个作业：

upload\-windows:
    runs\-on: windows\-latest
...
upload\-macos:
    runs\-on: macOS\-latest
...

签出源代码，设置Python，安装依赖项，安装诗歌，关闭virtualenvs，使用缓存以及诗歌安装Python依赖项的下一步与上面的应用程序Test Job完全相同。

接下来，我们构建wheel和sdist，这是使用Poetry时的单个命令：

      \- name: Build Wheel and sdist
        run: poetry build

我们针对Windows的打包使用的是运行 [PyInstaller的](https://www.pyinstaller.org) 自定义外壳程序脚本， 以打包应用程序，库和Python，并使用makensis来创建Windows安装程序。 我们还使用自定义外壳脚本来打包适用于macOS的应用程序。 执行脚本打包应用程序后，然后将发布资产上传到GitHub：

      \- name: Upload Assets
        uses: AButler/upload\-release\-assets@v2.0
        with:
          files: 'macos\-dmg/\*dmg;dist/\*;win\-installer/\*.exe'
          repo\-token: ${{ secrets.GITHUB\_TOKEN }}

在这里，我使用的是安德鲁·巴特勒（Andrew Butler）的 [上载\-释放\-资产](https://github.com/AButler/upload-release-assets) 动作。 GitHub还具有执行此操作的功能，称为 [upload\-release\-asset](https://github.com/actions/upload-release-asset) ，但在编写此文件时，它不支持使用通配符（称为全局模式）上传多个文件。 `secrets.GITHUB_TOKEN` 是另一个上下文表达式，用于获取访问令牌以允许Actions权限访问项目存储库，在这种情况下，将发布资源上载到草拟的发布中。

我用于跨平台应用程序的完整GitHub Actions工作流的最终版本已发布在 [Gaphor回购上](https://github.com/gaphor/gaphor/tree/master/.github/workflows) 。

### 我的工作流程的未来改进

我认为仍有一些机会可以通过更新现有操作或创建新操作来简化我创建的工作流程。 正如我之前提到的，最好在成熟度级别上运行，这样就不需要运行自定义环境变量，路径或Shell脚本。 相反，我们将以动作作为构建块来构建工作流。 在开始使用GitHub Actions之前，我没有想到这一点，但是我被卖掉了，它的功能非常强大。

自从GitHub最近发布了针对行动的CI / CD以来，许多GitHub提供的行动仍然可以使用一些技巧。 我想到的大多数改进之处，已经针对功能请求开放了问题，已经被其他人认可。 如果我们花一点时间，我相信这些会很快得到改善。

我还说过，我的目标之一是发布到三个主要平台，但是如果您在上一节中关注的话，我只提到Windows和macOS。 我们目前正在使用Flatpak for Linux打包应用程序，并通过 [FlatHub](https://flathub.org) 分发该应用程序 。 FlatHub确实具有自动构建系统，但是它需要清单文件，该清单文件存储在该应用程序的特殊单独FlatHub存储库中。 我还为 [Flatpak Builder Tools](https://github.com/flatpak/flatpak-builder-tools) 做出了贡献 ，以便从 `poetry.lock` 文件 自动生成所需的清单 。 这很好用，但是将来可以为我的应用程序提供CD工作流，并启动FlatHub存储库的更新。

### 奖金\-其他重大行动

[使用tmate进行调试](https://github.com/marketplace/actions/debugging-with-tmate) \-tmate是基于tmux构建的终端共享应用程序。 这项出色的操作使您可以在执行步骤的过程中暂停工作流，然后进入主机运行程序并调试配置。 在运行测试时遇到了Python分段错误，事实证明该操作非常有用。

[Release Drafter\-](https://github.com/marketplace/actions/release-drafter) 在我的App CD工作流程中，我显示了在创建或编辑发行版时正在执行它。 发布起草者操作根据合并的“拉取请求”使用发行说明来草拟我的下一个发行版。 然后，我只需要编辑发布以添加要发布的标签，我的所有发布资产就会自动上传。 该 [公关贴标](https://github.com/marketplace/actions/pr-labeler) 行动，这也随之而来基于分支名称模式，如标记您的引入请求 `feature/*` 。