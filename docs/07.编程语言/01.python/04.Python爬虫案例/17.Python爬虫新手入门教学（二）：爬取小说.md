本文的文字及图片来源于网络,仅供学习、交流使用,不具有任何商业用途,如有问题请及时联系我们以作处理。

[Python爬虫新手入门教学（一）：爬取豆瓣电影排行信息](https://www.toutiao.com/i6920863130977337859/?group_id=6920863130977337859)

*   Python 3.6
*   Pycharm
*   requests
*   parsel

安装Python并添加到环境变量，pip安装需要的相关模块即可。

![](https://p1-tt.byteimg.com/origin/pgc-image/e37ec9c1426142cfb4e263fca38f7721?from=pc)

![](https://p6-tt.byteimg.com/origin/pgc-image/b74d3883bb8149f9afd4c6eec32a8880?from=pc)

**爬取小说内容保存到本地**

*   小说名字
*   小说章节名字
*   小说内容
```py
 url = 'http://www.biquges.com/52_52642/25585323.html'
```

```py
url = 'http://www.biquges.com/52_52642/25585323.html'
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'
}
response = requests.get(url=url, headers=headers)
print(response.text)
```

![](https://p1-tt.byteimg.com/origin/pgc-image/98874de38707428dbec0328d3bd38c68?from=pc)

  
请求网页返回的数据中出现了乱码，这就需要我们转码了。

加一行代码自动转码。

```py
response.encoding = response.apparent_encoding
```

![](https://p3-tt.byteimg.com/origin/pgc-image/8ca819288e064d4090c9fa8573cfc6b3?from=pc)

![](https://p1-tt.byteimg.com/origin/pgc-image/b59efb64ad18450f8a502ec003148a85?from=pc)

  
根据css选择器可以直接提取小说标题以及小说内容。

```py
def get_one_novel(html_url):
    
    response = get_response(html_url)
    
    selector = parsel.Selector(response.text)
    
    title = selector.css('.bookname h1::text').get()
    
    content_list = selector.css('#content::text').getall()
    
    content_str = ''.join(content_list)
    print(title, content_str)

if __name__ == '__main__':
    url = 'http://www.biquges.com/52_52642/25585323.html'
    get_one_novel(url)
```

![](https://p1-tt.byteimg.com/origin/pgc-image/3e67254ebbe446f7b216799c8c7296e2?from=pc)

使用常用的保存方式： **with open**

```py
def save(title, content):
    """
    保存小说
    :param title: 小说章节标题
    :param content: 小说内容
    :return: 
    """
    
    filename = f'{title}\\'
    
    if os.makedirs(filename):
        os.mkdir()
    
    with open(filename + title + '.txt', mode='a', encoding='utf-8') as f:
        
        f.write(title)
        
        f.write('\n')
        
        f.write(content)
```

![](https://p1-tt.byteimg.com/origin/pgc-image/78c6a91fb2dc4787b3e1b75b2ba742bb?from=pc)

![](https://p6-tt.byteimg.com/origin/pgc-image/dc8499a459ba472794e463ad41a7319b?from=pc)

  
保存一章小说，就这样写完了，如果想要保存整本小说呢？

既然爬取单章小说知道怎么爬取了，那么只需要获取小说所有单章小说的url地址，就可以爬取全部小说内容了。

![](https://p6-tt.byteimg.com/origin/pgc-image/48eaf2bbc7244862b4aaf1c068a91417?from=pc)

  
所有的单章的url地址都在 dd 标签当中，但是这个url地址是不完整的，所以爬取下来的时候，要拼接url地址。

```py
def get_all_url(html_url):

    response = get_response(html_url)

    selector = parsel.Selector(response.text)

    dds = selector.css('#list dd a::attr(href)').getall()
    for dd in dds:
        novel_url = 'http://www.biquges.com' + dd
        print(novel_url)

if __name__ == '__main__':
    url = 'http://www.biquges.com/52_52642/index.html'
    get_all_url(url)
```

![](https://p6-tt.byteimg.com/origin/pgc-image/8650d2ceeb22474094ae748e0f3f2b2e?from=pc)

  
这样就获取了所有的小说章节url地址了。

```py
import requests
import parsel
from tqdm import tqdm

def get_response(html_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.138 Safari/537.36'
    }
    response = requests.get(url=html_url, headers=headers)
    response.encoding = response.apparent_encoding
    return response

def save(novel_name, title, content):
    """
    保存小说
    :param title: 小说章节标题
    :param content: 小说内容
    :return:
    """
    filename = f'{novel_name}' + '.txt'
    
    with open(filename, mode='a', encoding='utf-8') as f:
        
        f.write(title)
        
        f.write('\n')
        
        f.write(content)

def get_one_novel(name, novel_url):
    
    response = get_response(novel_url)
    
    selector = parsel.Selector(response.text)
    
    title = selector.css('.bookname h1::text').get()
    
    content_list = selector.css('#content::text').getall()
    
    content_str = ''.join(content_list)
    save(name, title, content_str)

def get_all_url(html_url):
    
    response = get_response(html_url)
    
    selector = parsel.Selector(response.text)
    
    dds = selector.css('#list dd a::attr(href)').getall()
    
    novel_name = selector.css('#info h1::text').get()
    for dd in tqdm(dds):
        novel_url = 'http://www.biquges.com' + dd
        get_one_novel(novel_name, novel_url)

if __name__ == '__main__':
    novel_id = input('输入书名ID：')
    url = f'http://www.biquges.com/{novel_id}/index.html'
    get_all_url(url)
```

![](https://p6-tt.byteimg.com/origin/pgc-image/cabb3a5fce2b480a8a94bc67b9bee9dd?from=pc)

![](https://p1-tt.byteimg.com/origin/pgc-image/779e83c277ac4add8d845bbaf7bdb04d?from=pc) 
 [https://www.toutiao.com/a6921602497219920395/](https://www.toutiao.com/a6921602497219920395/)